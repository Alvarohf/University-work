\documentclass [a4paper] {article}

\usepackage[utf8]{inputenc}


\title{\textbf{Practica 1: Fundamentos de la ciencia de datos}}
\author{Luis Alejandro Cabanillas, Alvaro de las Heras, Mohssin Nagib Najim}

\begin{document}

\maketitle

\section{Ejercicio 1} En la primera parte se realizará un ejercicio de prueba con distintos tipos de ficheros para probar la 
carga de datos en R. Una vez tengamos estos datos se procederá con su análisis. 

\subsection{Lectura y operaciones sobre .txt} 
Lo primero que vamos a hacer es la carga del fichero .txt en R. Este tipo de archivo es soportado directamente
por R sin necesidad de bibliotecas externas, al igual que el CSV. El archivo que se va a cargar contiene
los nombres de satélites del planeta Urano junto a sus radios. 
Para la carga del fichero utilizaremos la instrucción read.table("archivo.txt"). Tenemos que tener en cuenta que 
el archivo tiene que estar en el directorio actual de trabajo, sino deberemos introducir la ruta hasta el mismo.
Algunas instrucciones útiles relacionadas con el directorio de trabajo en R son:

\begin{itemize}
	\item \textbf{getwd()}: Nos proporciona el directorio de trabajo actual. 
	\item \textbf{setwd("directorio")}: Cambia el directorio de trabajo actual al directorio 
											especificado.
	\item \textbf{list.files()}: Muestra una lista de los archivos del directorio actual de trabajo.
														 
\end{itemize}

Asi, lo primero que tenemos que hacer es comprobar que el archivo satelites.txt se encuentra en el directorio de trabajo actual:
<<>>=
getwd()
list.files()

@
Como podemos ver, el archivo se encuentra en el directorio especificado, por lo que podemos hacer uso de read.table() para la carga de datos del fichero:
<<>>=
satelites<-read.table("satelites.txt")
satelites
@

Una vez que tenemos todos los datos cargados en R, procedemos a su análisis.

\subsubsection{Calculo del rango}
Para facilitar los cálculos, vamos a almacenar en una variable radio todos los radios de los satélites de Urano mediante el símbolo del dolar,  
que nos permite extraer subconjuntos en R:

<<>>=
radio=satelites$radio
radio

@
En R no tenemos ninguna funcion específica para calcular el rango, por lo que la emplearemos nosotros. Para ello, haremos uso de:
\begin{itemize}
	\item \textbf{max()}: Nos devuelve el valor máximo de uno o varios vectores.
	\item \textbf{min()}: Nos devuelve el valor mínimo de uno o varios vectores. 
																									 
\end{itemize}

De esta forma creamos la funcion rango y la aplicamos a nuestro problema:
<<>>=
rango = function(radio){max(radio)-min(radio)}
rang = rango(radio)

@

El rango obtenido es \Sexpr{rang}

Para guardar la función rango creada haremos uso de dos funciones de R:
\begin{itemize}
	\item \textbf{dump("nombre funcion","nombre archivo")}: Crea y guarda en un archivo la función especificada.
	\item \textbf{source("nombre archivo")}: Lee el archivo .R que le pasemos.
																									 
\end{itemize}

De esta forma:
<<>>=
dump("rango", file="rango.R")
source("rango.R")

@

\subsubsection{Cálculo de frecuencias}
\paragraph{Frecuencia absoluta}
Para el cálculo de la frecuencia absoluta haremos uso de la función \textbf{table("vector")} de R, que
creará una tabla en la que aparecerá cuantas veces aparece cada radio:
<<>>=
frecabsradio <- table(radio)
frecabsradio

@
Vemos que todos los radios aparecen una vez, salvo el 20 que aparece dos veces.

\paragraph{Frecuencia absoluta acumulada.}
El cálculo de la frecuencia absoluta acumulada será muy sencillo, ya que lo único que tenemos que
hacer es llamar a la función \textbf{cumsum("vector")} de R, que irá calculando la suma acumulada
de las frecuencias absolutas calculadas anteriormente.
<<>>=
frecabsacumradio <- cumsum(frecabsradio)
frecabsacumradio
@

\paragraph{Frecuencia relativa.}
En R no tenemos una funcion que nos calcule las frecuencias relativas, asi que tendremos que crearla
nosotros haciendo uso de la fórmula:
<<>>=
frecrel = function(radio){table(radio)/length(radio)}
frecrel(radio)
@

Como el radio=20 es el único que aparece dos veces, su frecuencia relativa es diferente a la del resto.

\paragraph{Frecuencia relativa acumulada.}
Para el cálculo de la frecuencia relativa acumulada únicamente tendremos que hacer una suma acumulada de
las frecuencias relativas obtenidas en el apartado anterior:
<<>>=
frecrelacumradio <- cumsum(frecrel(radio))
frecrelacumradio
@

\subsubsection{Cálculo de la media aritmética}
Para el cálculo de la media aritmética en R tenemos la función \textbf{mean("vector")}, que
nos devuelve la media aritmética de una serie de valores almacenados en un vector. Así:
<<>>=
media<-mean(radio)
media
@

La media obtenida es \Sexpr{media}

\subsubsection{Medidas de dispersion}
\paragraph{Desviacion tipica.}
R nos proporciona \textbf{sd("vector")} para el cálculo de la desviación típica:
<<>>=
desTip<-sd(radio)
desTip
@
La desviación típica obtenida es \Sexpr{desTip}
\paragraph{Varianza.}
Para la varianza también tenemos una formula específica en R, \textbf{var("vector")}.
<<>>=
var<-var(radio)
var
@
La varianza obtenida es \Sexpr{var}

\subsubsection{Medidas de ordenacion}
\paragraph{Mediana.}
La función que nos hace la mediana en R es \textbf{median("vector")}.
<<>>=
med<-median(radio)
med
@
La mediana obtenida es \Sexpr{med}

\paragraph{Cuartiles.}
De nuevo, tenemos una función en R que nos calcula los cuartiles: \textbf{quantile("vector")}.
<<>>=
cuart<-quantile(radio)
cuart
@
Los cuartiles obtenidos son \Sexpr{paste(cuart, collapse=", ")}

\paragraph{Cuantil 54.}
Para calcular el cuantil 54 lo único que tenemos que hacer es pasarle un argumento más a la función
quantile, indicándole el cuantil que queremos:
<<>>=
cuart54<-quantile(radio,0.54)
cuart54
@
El cuartil 54 obtenido es \Sexpr{cuart54}


\subsection{Lectura y operaciones sobre .sav} 
En este apartado realizaremos el análisis sobre un tipo de fichero .sav, para cargarlo en R tendremos
que utilizar una biblioteca externa pero disponible para su inclusión fácilmente. El archivo .sav contiene datos
de automóviles, como su consumo en mpg (millas por galón), cilindrada, aceleración, etc. Para la carga de este
fichero primero debemos importar la biblioteca foreign con la instrucción \textbf{library(foreign)}, para posteriormente
poder leer el archivo .sav con la instrucción \textbf{read.spss("archivo.sav")}. 

@
Realizamos la carga de datos con el archivo .sav en nuestro directorio actual, como solo se nos pide analizar el dato de mpg mostraremos solo ese dato:
<<>>=
library(foreign)
autos<-read.spss("cardata.sav")
mpg = autos$mpg
mpg
@

@
\subsubsection{Calculo del rango}
Para facilitar los cálculos, vamos a almacenar en una variable radio todos los radios de los satélites de Urano mediante el símbolo del dolar,  
que nos permite extraer subconjuntos en R, para poder realizar esta operación tenemos que eliminar todos los datos NA que contiene la variable mpg,
esto lo haremos con la función \textbf{na.omit("vector")} que nos devolverá los datos sin los NA para poder operar el rango:

<<>>=
nmpg <- na.omit(mpg)
rangmpg <- rango(nmpg)
rangmpg
@

El rango obtenido es \Sexpr{rangmpg}

@
\subsubsection{Calculo de la media aritmética}
Para el cálculo de la media aritmetica en R utilizaremos la función \textbf{mean("vector")} como hicimos previamente que nos devolverá la media aritmética de
una serie de valores almacenados en un vector, realizamos la misma operación con los valores NA del vector:
<<>>=
mediampg <- mean(nmpg)
mediampg
@

La media obtenida es \Sexpr{mediampg}


\subsubsection{Medidas de dispersión}
\paragraph{Desviación típica.}
R nos proporciona \textbf{sd("vector")} para el cálculo de la desviación típica:
<<>>=
desTipmpg<-sd(nmpg)
desTipmpg
@
La desviación típica obtenida es \Sexpr{desTipmpg}
\paragraph{Varianza.}
Para la varianza también tenemos una fórmula específica en R, \textbf{var("vector")}.
<<>>=
varmpg<-var(nmpg)
varmpg
@
La varianza obtenida es \Sexpr{varmpg}

\subsubsection{Medidas de ordenación}
\paragraph{Mediana.}
La función que nos hace la mediana en R es \textbf{median("vector")}.
<<>>=
medmpg<-median(nmpg)
medmpg
@

La mediana obtenida es \Sexpr{medmpg}

\paragraph{Cuartiles.}
De nuevo, tenemos una función en R que nos calcula los cuartiles: \textbf{quantile("vector")}.
<<>>=
cuartmpg<-quantile(nmpg)
cuartmpg
@

Los cuartiles obtenidos son \Sexpr{paste(cuartmpg, collapse=", ")}

\section{Ejercicio 2}
En este ejercicio se realizará un análisis a partir de un dataset de jugadores de fútbol del videojuego FIFA 19.

\subsection{Lectura del dataset}
El dataset sobre los jugadores ha sido obtenido en Kaggle, estando por defecto en formato CSV, teniendo un total de 91 columnas y 18206 filas. Sin embargo, para dar más juego
al ejercicio hemos convertido los datos a otros formatos muy utilizados como son JSON y Excel. Las conversiones las hemos hecho con el propio 
Excel y con un conversor on-line de CSV a JSON.

\subsubsection{Archivo CSV con filtro en la lectura}
La forma más sencilla de obtener los datos es leyendo el CSV, al estar integrada en el propio R.
Además se ha realizado un filtro de columnas en la lectura mediante el parámetro colClasses, poniendo el tipo deseado para las que nos interesan 
y dejando a NULL las que no, de esta forma
se consigue una lectura del archivo mucho más rápida. Otros parámetros que también se han usado han sido nrows para filtrar filas y encoding 
para poner los datos en UTF8.

<<>>=
filas <- 6000
# Lectura del CSV
columnas<-c("NULL","NULL","character","numeric","NULL","character","NULL","numeric",
"numeric","character","NULL","character","character",rep("NULL",76))
csv <- read.csv("Fifa\\fifa19.csv",head=T,sep=",",
encoding = "UTF-8",colClasses=columnas,nrows=filas)
head(csv,10)
@

\subsubsection{Archivo JSON}
Para la lectura del archivo JSON se ha usado la función read json que ofrece jsonlite, aunque en un principio se hizo con rjson se descarto por su baja eficiencia. 
A diferencia del CSV, aquí no se pueden quitar columnas en la lectura sino que ha de ser sobre 
el conjunto de datos ya cargados, haciendolo más lento que el primero. Con el parámetro simplify = simplifyVector 
conseguimos que el resultado sea un data.frame de R, con el que trabajar más fácilmente. 

<<>>=
install.packages("jsonlite")
library("jsonlite")
json<-read_json("Fifa\\fifa19.json", simplifyVector=TRUE)
json<- json[-((6001):19000), -c(1,2,5,7,11,14:89)]
head(json,10)
@

\subsubsection{Archivo Excel}
La lectura del Excel se realiza con la biblioteca readxl de CRAN. Para ello se usa el método read excel, este permite la lectura tanto de formatos xls como de xlsx. 
Como en el caso anterior las columnas no se pueden filtrar en la lectura, por lo que ha de hacerse después. Sin embargo, si permite limitar las filas 
con el parámetro n max.

<<>>=
install.packages("readxl")
library("readxl")
excel <- read_excel("Fifa\\fifa19.xlsx", n_max=6000)
excel<- excel[, -c(1,2,5,7,11,14:89)]
head(excel,10)
@

Una vez visto el proceso de carga de datos, cualquiera de los que hemos cargado servirán para realizar el análisis.

<<>>=
edades <- excel$Age
equipos <- json$Club
nacionalidades <-csv$Nationality
puntuaciones <- csv$Overall
@

\subsection{Frecuencias de los datos}
En el primer análisis de datos que vamos a realizar veremos las distintas frecuencias sobre las edades y los equipos. Hemos elegido
estas dos variables al ser una numérica y otra de cadena de texto. Con estos datos se pueden ver las edades y equipos con más jugadores en el juego.
Al no ser númerica realizar la frecuencia acumulada sobre los equipos no tenía mucho sentido. Para calcularlas se han usado las funciones 
\textbf{table()} y \textbf{cumsum()} .
Finalmente se han representado con histogramas y gráficos de barras con respecto a la visualización de los equipos se observa que hay un primer 
grupo que destaca, este 
se corresponde con los jugadores que no tienen un equipo, usando las funciones textbf{hist()} y textbf{barplot()} que se han 
personalizado cambiando colores y etiquetas.

<<>>=
frecAbsEdad<-table(edades )
frecAbsEdad
fAbsAcumEdad<-cumsum(frecAbsEdad)
fAbsAcumEdad
frecRelEdad<-table(edades )/length(edades )
frecRelEdad
fRelAcumEdad<-cumsum(frecRelEdad)
fRelAcumEdad
frecAbsEquipos<-table(equipos)
head(frecAbsEquipos,20)
fAbsAcumEquipos<-cumsum(frecAbsEquipos)
frecRelEquipos<-table(equipos )/length(equipos )
head(frecRelEquipos,20)
@

<<histo, eval=FALSE>>=
hist(edades, col = "orange", main = "Histograma de edades",
     xlab = "Edades", ylab = "Frecuencia")
@

<<barp, eval=FALSE>>=   
barplot(frecAbsEquipos,col = "blue", main = "Frecuencias de equipos",  xlab = "Equipos", ylab = "Jugadores")
@

\begin{center}
<<fig=TRUE, echo=FALSE>>=
library("graphics")
<<histo>>
@
\end{center}

\begin{center}
<<fig=TRUE, echo=FALSE>>=
library("graphics")
<<barp>>
@
\end{center}

\subsection{Medidas de centralización}
Dentro de esta sección mostraremos todas las medidas que intentan resumir los datos con un solo número, mediante la media aritmética,
la moda y la mediana.

\subsubsection{Media aritmética}
La media aritmética nos permite hacernos una idea de los valores promedios de una forma independiente, en este caso hemos calculado la media de las edades,
las medias agrupadas por equipos y nacionalidades, y la media agrupada en clases de edades. Todas ellas se han realizado con textbf{mean()}; aunque han requerido
de variaciones para las agrupaciones que se han realizado con textbf{aggregate()} en el caso de las no númericas y de textbf{cut()} junto a
 textbf{tapply()} de las númericas.
Dentro de textbf{aggregate()} se ha tenido que indicar las columnas sobre las que realizar las medias junto a la columna encargada de la 
agrupación (equipos y nacionalidades), 
además de la operación de media textbf{mean()}. Con las clases númericas ha sido necesario primero establecer el corte textbf{cut()} 
 para ello cogiendo la variable e indicando los 
cortes (breaks). Una vez definidas las clases, se ha usado textbf{tapply()} para aplicar el vector a los datos que queremos promediar, 
para ello pasando las clases, los datos y la función textbf{mean()}.

<<>>=
mediaEdad <- mean(edades )
mediaPuntos <- mean(puntuaciones )
head(aggregate(csv[, c(2,4,5)], list(equipos), mean),20)
head(aggregate(csv[, c(2,4,5)], list(nacionalidades), mean),20)
clases <- cut(edades, breaks = c(10,20,30,40,50))
mediaClases <- tapply(puntuaciones, list(clases ), mean)
mediaClases 
mediaEquipos <- tapply(puntuaciones, list(equipos,clases ), mean)
head(mediaEquipos ,20)
@

En cuanto a la visualización de los datos se ha optado por un gráfico en el que se muestran todas las medias de las clases generado con textbf{plot()}, al 
que se le ha indicado que muestre las marcas de clases y las puntuaciones asociadas indicándose con puntos y líneas. Además, se ha añadido un punto, que representa
la media de las edades y puntuaciones con la función textbf{points()}. Finalmente se ha añadido una etiqueta al punto con la función textbf{text()}, a la que se ha tenido
que indicar además la posición para que no se superponga con el punto.

<<pl, eval=FALSE>>=
plot(
        seq(15, 45, by= 10),
        mediaClases,
        type="b",
        col="red",
        main="Medias",
        xlab="Clases",
        ylab="Puntuaciones")
points(mediaEdad,mediaPuntos,pch=24,col="blue",bg="blue")
text(mediaEdad,mediaPuntos, labels="Media de edad y puntuacion", cex= 0.7, pos=4)
@

\begin{center}
<<fig=TRUE, echo=FALSE>>=
library("graphics")
<<pl>>
@
\end{center}

\subsubsection{ Moda}
La moda permite saber el valor que con más frecuencia sale en la distribución de los datos, en este caso R no tenía ninguna función hecha para ello, por lo
que hemos realizado una función que lo haga. Esta función que recibe un vector por parámetro, lo primero que hace es generar 
uno quitando los duplicados contextbf{unique()}  , de tal forma
que a posteriori lo comparará con el original para contar coincidencias y devolver el mayor.

<<>>=
moda <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
@

Con la función ya terminada solo queda probarla sobre nuestros datos, en este caso sobre puntuaciones, nacionalidades y equipos.

<<>>=
moda(puntuaciones)
moda(nacionalidades )
moda(equipos)
@

Como se ha podido ver equipos ha devuelto "", no se trata de un error si no que lo más frecuente de las distribución son jugadores sin equipo. Para arreglar esto
y ver cual es el equipo más representado en la muestra modificamos la variable de equipos quitando los que no tienen equipo.

<<>>=
equipos<-equipos[equipos != ""]
moda(equipos)
@

\subsubsection{ Mediana}
La mediana es el valor del punto medio de un conjunto ordenado, sabiendo así la tendencia central. Para su cálculo hemos empleado el método
\textbf{median()}, que nos permite calcularla de forma directa.

<<>>=
medianaEdades <- median(edades)
medianaEdades 
medianaPuntuaciones <- median(puntuaciones)
medianaPuntuaciones 
@

\subsection{Medidas de ordenación}
Las medidas de ordenación, también conocidas como medidas de posición, son los valores de la variable, que ordenados de menor a mayor, dividen a la distribución en partes.

\subsubsection{ Cuantiles}
En este caso aplicaremos diversos cuantiles, siendo la primera la división en cuartiles y la siguiente en deciles, ambas realizadas con la función que incluye \textbf{quantile()}.

<<>>=
cuartiles <- quantile(puntuaciones,seq(0,1, by=0.25))
cuartiles 
deciles<-quantile(puntuaciones, probs = seq(0, 1, by= 0.1))
deciles
@

<<boxp, eval=FALSE>>=
boxplot(puntuaciones, col="orange", 
        main = "Cuantiles de puntuaciones",
        ylab = "Puntuaciones")
@

\begin{center}
<<fig=TRUE, echo=FALSE>>=
library("graphics")
<<boxp>>
@
\end{center}

\subsection{Medidas de dispersión}
Estas medidas sirven para mostrar la variabilidad de la distribución con respecto a las medidas de centralización. Trataremos los rangos, rangos intercuartílicos, desviaciones típicas, 
varianzas y el coeficiente variación. Además también trataremos variaciones conjuntas con la covarianza y el coeficiente de correlación.

\subsubsection{ Rango}
El rango es el valor entre el máximo y el mínimo de los datos para saber de forma sencilla la dispersión de los datos, permitiendo ver el recorrido. En este caso
como se ha explicado en el anterior ejercicio se ha tenido que hacer con las funciones \textbf{min()} y \textbf{max()}.

<<>>=
rangoEdades<-(max(edades )-min(edades ))
rangoEdades
rangoPuntuaciones<-(max(puntuaciones )-min(puntuaciones ))
rangoPuntuaciones
@

\subsubsection{ Rango intercuartílico}
El rango intercuartílico a diferencia del rango, es un estadístico robusto (no se ve afectada por valores atípicos). Este consiste en calcular la diferencia entre el 
tercer cuartil y el primer cuartil, el propio R ya incluye la función \textbf{IQR()} que lo realiza sobre los datos. Se ha podido observar en el diagrama de caja que teníamos.

<<>>=
rangoInterC <- IQR(edades)
rangoInterC
@

\subsubsection{ Desviación típica}
La desviación típica sirve para mostrar la variación entre los datos con respecto a la media aritmética. En este caso hemos empleado la función \textbf{sd()} que
la calcula directamente sobre el vector que recibe. En este caso es un valor algo alto lo que indica que produce variaciones de varias unidades con respecto a ambas medias.

<<>>=
desviacionEdades <- sd(edades)
desviacionEdades 
desviacionPuntos <- sd(puntuaciones)
desviacionPuntos 
head(aggregate(csv[, c(2,4,5)], list(nacionalidades), sd),20)
@

\subsubsection{ Varianza}
La varianza permite al igual que la desviación típica calcular las variaciones de los datos, aunque con las unidades al cuadrado. En este caso se
hará directamente con la función \textbf{var()}. Al igual que antes los datos arrojados permiten ver que las variaciones son significantes.

<<>>=
varianzaEdades <- var(edades)
varianzaEdades 
var(puntuaciones)
@

\subsubsection{ Coeficiente de variación}
El coeficiente de variación es la relación entre la media y la variabilidad de la variable. Para calcularlo solo hace falta dividir la desviación típica con respecto a su media, en este
caso es baja lo que indica que a pesar de que parezca que hay bastante desviación típica, no lo es con respecto a la media.

<<>>=
coefVariacion <- desviacionEdades/mediaEdad
coefVariacion
@

\subsubsection{ Covarianza}
La covarianza es un valor que nos indical a variación conjunta de dos variables con respecto a sus medias, permitiendo saber si existe una dependencia entre ambas variables.
Se aplica en R mediante la función \textbf{cov()} que se encarga de realizar la covarianza entre las dos variables que reciba. En nuestros datos la covarianza tiene un valor muy bajo lo
que indica que la dependencia entre las variables de edades y puntuaciones es muy baja.

<<>>=
covarianza<-cov(edades, puntuaciones)  
covarianza
@

\subsubsection{ Coeficiente de correlación}
La correlación indica la fuerza dirección de una relación lineal entre dos variables variando entre -1 y 1. Según estos valores se acerquen a los extremos tendrán mayor fuerza pudiendo ser negativa
o positiva si son lineales o inversas las relaciones, si se acerca al 0 no hay relación alguna. En nuestro caso tiene un valor muy próximo a 0 por lo que no hay relación alguna entre ambas.

<<>>=
cor(edades, puntuaciones)
@


\end{document}